# Simple RAG Project - Code Documentation

## Overview

This is a Retrieval-Augmented Generation (RAG) system built in Go that allows users to:

- Ingest documents and convert them to vector embeddings
- Query the system with questions and get AI-generated answers
- Store and retrieve relevant documents using Pinecone vector database

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   HTTP Client   â”‚â”€â”€â”€â–¶â”‚   HTTP Server   â”‚â”€â”€â”€â–¶â”‚   RAG Service    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                      â”‚
                                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OpenAI API    â”‚â—€â”€â”€â”€â”‚  Embedding      â”‚â—€â”€â”€â”€â”‚  Vector Store   â”‚
â”‚   (Embeddings)  â”‚    â”‚  Service        â”‚    â”‚  (Pinecone)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                      â”‚
                                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Simple LLM    â”‚â—€â”€â”€â”€â”‚  Response       â”‚â—€â”€â”€â”€â”‚  Document       â”‚
â”‚   (Answer Gen)  â”‚    â”‚  Generation     â”‚    â”‚  Retrieval      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## File: `models/models.go`

### Package: `models`

### Data Structures

#### `Document` struct

```go
type Document struct {
    ID        string    `json:"id"`        // Unique identifier for the document
    Content   string    `json:"content"`   // The actual text content
    Embedding []float32 `json:"embedding"` // Vector representation (1536 dimensions for OpenAI)
}
```

**Purpose**: Represents a document with its vector embedding for storage and retrieval.

**Fields**:

- `ID`: Unique identifier (e.g., "doc_001", "article_123")
- `Content`: The actual text content of the document
- `Embedding`: Vector representation (array of float32 values) created by OpenAI's embedding model

**Usage Flow**:

1. Created when ingesting documents
2. Embedding field populated by OpenAI service
3. Stored in Pinecone vector database
4. Retrieved during search operations
5. Used in answer generation

#### `QueryRequest` struct

```go
type QueryRequest struct {
    Question string `json:"question"` // User's question
    TopK     int    `json:"top_k"`    // Number of similar documents to retrieve
}
```

**Purpose**: Request structure for user queries.

**Fields**:

- `Question`: The user's question (e.g., "What is machine learning?")
- `TopK`: Number of most similar documents to retrieve (default: 3)

**Request Flow**:

1. HTTP POST to `/query` endpoint
2. JSON unmarshaled into QueryRequest
3. Passed to RAGService.Query()
4. Question converted to embedding
5. TopK used for vector search

#### `QueryResponse` struct

```go
type QueryResponse struct {
    Answer  string     `json:"answer"`  // Generated answer
    Sources []Document `json:"sources"` // Documents used for answer
}
```

**Purpose**: Response structure containing the generated answer and source documents.

**Fields**:

- `Answer`: AI-generated answer based on retrieved documents
- `Sources`: Array of documents that were used to generate the answer

**Response Flow**:

1. Generated by RAGService.Query()
2. Answer created by SimpleLLM
3. Sources populated from vector search
4. JSON marshaled for HTTP response
5. Sent back to client

#### `IngestionRequest` struct

```go
type IngestionRequest struct {
    Documents []Document `json:"documents"` // List of documents to add
}
```

**Purpose**: Request structure for adding documents to the system.

**Fields**:

- `Documents`: Array of documents to be embedded and stored

**Ingestion Flow**:

1. HTTP POST to `/ingest` endpoint
2. JSON unmarshaled into IngestionRequest
3. Each document processed individually
4. Embeddings generated for each document
5. Documents stored in Pinecone

---

## File: `models/interfaces.go`

### Package: `models`

#### `RAGService` interface

```go
type RAGService interface {
    Query(request QueryRequest) (*QueryResponse, error)
    Ingest(request IngestionRequest) error
}
```

**Purpose**: Defines the contract for RAG operations.

**Methods**:

- `Query(request QueryRequest)`: Processes user questions and returns answers
- `Ingest(request IngestionRequest)`: Adds new documents to the system

**Interface Implementation**:

- Implemented by `services.RAGService` struct
- Used by HTTP handlers for dependency injection
- Enables testing with mock implementations

---

## File: `services/openai_service.go`

### Package: `services`

### `OpenAIEmbedder` struct

#### Overview

Handles text-to-vector conversion using OpenAI's embedding API.

#### Fields

```go
type OpenAIEmbedder struct {
    BaseURL string      // OpenAI API base URL
    Client  *http.Client // HTTP client with timeout
    APIKey  string      // OpenAI API key
}
```

#### Constructor

```go
func NewOpenAIEmbedder() *OpenAIEmbedder
```

**Purpose**: Creates a new OpenAI embedder instance with default configuration.

**Configuration**:

- Base URL: `https://api.openai.com/v1`
- Timeout: 30 seconds
- Model: `text-embedding-3-small` (cost-effective option)

#### Methods

##### `CreateEmbedding(text string) ([]float32, error)`

**Purpose**: Converts text to vector embedding using OpenAI API.

**Parameters**:

- `text`: Input text to be embedded

**Returns**:

- `[]float32`: Vector embedding (1536 dimensions)
- `error`: API errors or network issues

**Complete Method Flow**:

```go
func (e *OpenAIEmbedder) CreateEmbedding(text string) ([]float32, error) {
    // 1. Create request payload
    reqBody := map[string]interface{}{
        "model": "text-embedding-3-small",
        "input": text,
    }
    jsonData, _ := json.Marshal(reqBody)

    // 2. Create HTTP request
    req, _ := http.NewRequest("POST", e.BaseURL+"/embeddings", bytes.NewBuffer(jsonData))
    req.Header.Add("Content-Type", "application/json")
    req.Header.Add("Authorization", "Bearer "+e.APIKey)

    // 3. Execute HTTP request
    resp, err := e.Client.Do(req)
    if err != nil {
        return nil, fmt.Errorf("OpenAI error: %v", err)
    }
    defer resp.Body.Close()

    // 4. Read response body
    body, _ := io.ReadAll(resp.Body)
    fmt.Println("Embedding API response:", string(body))

    // 5. Check HTTP status
    if resp.StatusCode != http.StatusOK {
        return nil, fmt.Errorf("embedding request failed: %s", string(body))
    }

    // 6. Parse JSON response
    var result struct {
        Data []struct {
            Embedding []float32 `json:"embedding"`
        } `json:"data"`
    }
    if err := json.Unmarshal(body, &result); err != nil {
        return nil, fmt.Errorf("failed to parse response: %v", err)
    }

    // 7. Validate and return embedding
    if len(result.Data) == 0 {
        return nil, fmt.Errorf("no embedding received: %s", string(body))
    }
    return result.Data[0].Embedding, nil
}
```

**Error Handling**:

- Network errors
- API authentication failures
- Invalid response format
- Empty embedding responses

**Usage in RAG Pipeline**:

1. Called by RAGService.Query() for question embedding
2. Called by RAGService.Ingest() for document embedding
3. Returns 1536-dimensional vector for Pinecone storage

---

## File: `services/pinecone_service.go`

### Package: `services`

### `VectorStore` struct

#### Overview

Manages vector storage and retrieval using Pinecone vector database.

#### Fields

```go
type VectorStore struct {
    Client    *pinecone.Client // Pinecone client instance
    IndexHost string           // Pinecone index host URL
}
```

#### Constructor

```go
func NewVectorStore(client *pinecone.Client, indexHost string) *VectorStore
```

**Purpose**: Creates a new vector store instance.

**Parameters**:

- `client`: Pinecone client with API key
- `indexHost`: Pinecone index host URL

#### Methods

##### `Upsert(documents []models.Document) error`

**Purpose**: Stores documents as vectors in Pinecone.

**Parameters**:

- `documents`: Array of documents with embeddings

**Complete Method Flow**:

```go
func (v *VectorStore) Upsert(documents []models.Document) error {
    ctx := context.Background()

    // 1. Connect to Pinecone index
    index, err := v.Client.Index(pinecone.NewIndexConnParams{
        Host: v.IndexHost,
    })
    if err != nil {
        return fmt.Errorf("failed to connect to index: %v", err)
    }

    // 2. Create vectors with metadata
    vectors := make([]pinecone.Vector, 0, len(documents))
    for i, doc := range documents {
        fmt.Printf(">>>>> Document %d: ID=%s, Embedding=%d dimensions\n", i+1, doc.ID, len(doc.Embedding))

        // 3. Create metadata using structpb
        metadata, err := structpb.NewStruct(map[string]interface{}{
            "content": doc.Content,
        })
        if err != nil {
            return fmt.Errorf("failed to create metadata: %v", err)
        }

        // 4. Create embedding copy for pointer
        embeddingCopy := make([]float32, len(doc.Embedding))
        copy(embeddingCopy, doc.Embedding)

        // 5. Create Pinecone Vector
        vectors = append(vectors, pinecone.Vector{
            Id:       doc.ID,
            Values:   &embeddingCopy,   // Pointer to []float32
            Metadata: metadata,         // structpb.Struct
        })
    }

    // 6. Convert to pointers for UpsertVectors
    vectorPointers := make([]*pinecone.Vector, len(vectors))
    for i := range vectors {
        vectorPointers[i] = &vectors[i]
    }

    // 7. Execute upsert
    _, err = index.UpsertVectors(ctx, vectorPointers)
    if err != nil {
        return fmt.Errorf("failed to upsert vectors: %v", err)
    }

    fmt.Printf(">>>>> Successfully upserted %d vectors\n", len(vectors))
    return nil
}
```

**Vector Structure**:

```go
pinecone.Vector{
    Id:       doc.ID,           // Document identifier
    Values:   &embeddingCopy,   // Pointer to embedding array
    Metadata: metadata,         // Content metadata
}
```

**Error Handling**:

- Index connection failures
- Vector upsert errors
- Metadata conversion errors

**Usage in RAG Pipeline**:

1. Called by RAGService.Ingest() after document embedding
2. Stores vectors in Pinecone for similarity search
3. Metadata preserves original document content

##### `Search(embedding []float32, topK int) ([]models.Document, error)`

**Purpose**: Searches for similar documents using vector similarity.

**Parameters**:

- `embedding`: Query vector (1536 dimensions)
- `topK`: Number of results to return (default: 5)

**Returns**:

- `[]models.Document`: Array of similar documents
- `error`: Search errors

**Complete Method Flow**:

```go
func (v *VectorStore) Search(embedding []float32, topK int) ([]models.Document, error) {
    if topK == 0 {
        topK = 5
    }

    ctx := context.Background()
  
    // 1. Connect to Pinecone index
    index, err := v.Client.Index(pinecone.NewIndexConnParams{
        Host: v.IndexHost,
    })
    if err != nil {
        return nil, err
    }

    fmt.Printf("ðŸ” Searching with %d-dimensional vector, topK=%d\n", len(embedding), topK)

    // 2. Execute search using SearchRecords
    res, err := index.SearchRecords(ctx, &pinecone.SearchRecordsRequest{
        Query: pinecone.SearchRecordsQuery{
            TopK: int32(topK),
            Vector: &pinecone.SearchRecordsVector{
                Values: &embedding, // This should work since UpsertVectors stores the vectors
            },
        },
        Fields: &[]string{"content"}, // Request the content field back
    })
    if err != nil {
        return nil, err
    }

    fmt.Printf("ðŸ“Š Search found %d matches\n", len(res.Result.Hits))

    // 3. Process search results
    documents := make([]models.Document, len(res.Result.Hits))
    for i, hit := range res.Result.Hits {
        content := ""
        if hit.Fields != nil {
            if contentVal, ok := hit.Fields["content"]; ok {
                if contentStr, ok := contentVal.(string); ok {
                    content = contentStr
                }
            }
        }

        fmt.Printf("   Match %d: %s (score: %.3f)\n", i+1, hit.Id, hit.Score)
        documents[i] = models.Document{
            ID:      hit.Id,
            Content: content,
        }
    }

    return documents, nil
}
```

**Search Configuration**:

- Uses cosine similarity
- Returns top K most similar vectors
- Includes metadata fields in response

**Usage in RAG Pipeline**:

1. Called by RAGService.Query() with question embedding
2. Returns similar documents for answer generation
3. Content extracted from Pinecone metadata fields

---

## File: `services/rag_service.go`

### Package: `services`

### `RAGService` struct

#### Overview

Orchestrates the complete RAG pipeline: embedding â†’ retrieval â†’ generation.

#### Fields

```go
type RAGService struct {
    Embedder *OpenAIEmbedder // Text embedding service
    Store    *VectorStore    // Vector storage and retrieval
    LLM      *SimpleLLM      // Answer generation
}
```

#### Constructor

```go
func NewRAGService(embedder *OpenAIEmbedder, store *VectorStore, llm *SimpleLLM) *RAGService
```

**Purpose**: Creates RAG service with all required components.

#### Methods

##### `Query(request models.QueryRequest) (*models.QueryResponse, error)`

**Purpose**: Processes user questions through the complete RAG pipeline.

**RAG Pipeline**:

1. **Embedding**: Convert question to vector using OpenAI
2. **Retrieval**: Find similar documents in Pinecone
3. **Generation**: Generate answer using retrieved documents

**Parameters**:

- `request`: User's question and search parameters

**Returns**:

- `*models.QueryResponse`: Answer and source documents
- `error`: Pipeline errors

**Complete Method Flow**:

```go
func (r *RAGService) Query(request models.QueryRequest) (*models.QueryResponse, error) {
    fmt.Printf("ðŸ” Processing question: %s\n", request.Question)

    // 1. Convert question to embedding
    embedding, err := r.Embedder.CreateEmbedding(request.Question)
    if err != nil {
        return nil, fmt.Errorf("embedding failed: %v", err)
    }

    // 2. Set default topK if not specified
    topK := request.TopK
    if topK == 0 {
        topK = 3
    }

    // 3. Search for similar documents
    documents, err := r.Store.Search(embedding, topK)
    if err != nil {
        return nil, fmt.Errorf("search failed: %v", err)
    }

    fmt.Printf("ðŸ“š Found %d relevant documents\n", len(documents))

    // 4. Generate answer using retrieved documents
    answer := r.LLM.GenerateResponse(request.Question, documents)

    // 5. Return response with answer and sources
    return &models.QueryResponse{
        Answer:  answer,
        Sources: documents,
    }, nil
}
```

**Process Flow**:

```
Question â†’ Embedding â†’ Vector Search â†’ Document Retrieval â†’ Answer Generation
```

**Error Handling**:

- Embedding failures
- Vector search errors
- Answer generation issues

**Usage in HTTP Handler**:

1. Called by QueryHandler.ServeHTTP()
2. Processes user questions from /query endpoint
3. Returns structured response with answer and sources

##### `Ingest(request models.IngestionRequest) error`

**Purpose**: Adds new documents to the knowledge base.

**Process**:

1. **Embedding**: Convert each document to vector
2. **Storage**: Store vectors in Pinecone
3. **Validation**: Ensure successful storage

**Parameters**:

- `request`: Documents to be added

**Returns**:

- `error`: Ingestion failures

**Complete Method Flow**:

```go
func (r *RAGService) Ingest(request models.IngestionRequest) error {
    fmt.Printf(">>>>> Ingesting %d documents...\n", len(request.Documents))

    // 1. Process each document individually
    for i := range request.Documents {
        // 2. Generate embedding for document content
        embedding, err := r.Embedder.CreateEmbedding(request.Documents[i].Content)
        if err != nil {
            return fmt.Errorf("failed to embed document %s: %v", request.Documents[i].ID, err)
        }
      
        // 3. Store embedding in document
        request.Documents[i].Embedding = embedding
    }

    // 4. Store all documents in Pinecone
    if err := r.Store.Upsert(request.Documents); err != nil {
        return fmt.Errorf("failed to store documents: %v", err)
    }

    fmt.Println(">>>>> Documents ingested successfully!")
    return nil
}
```

**Batch Processing**:

- Processes multiple documents
- Handles individual document failures
- Continues processing on errors

**Usage in HTTP Handler**:

1. Called by IngestHandler.ServeHTTP()
2. Processes documents from /ingest endpoint
3. Returns success confirmation

---

## File: `services/simple_llm.go`

### Package: `services`

### `SimpleLLM` struct

#### Overview

Generates human-readable answers from retrieved documents.

#### Constructor

```go
func NewSimpleLLM() *SimpleLLM
```

**Purpose**: Creates a simple LLM instance for answer generation.

#### Methods

##### `GenerateResponse(question string, documents []models.Document) string`

**Purpose**: Creates comprehensive answers from retrieved documents.

**Parameters**:

- `question`: User's original question
- `documents`: Retrieved relevant documents

**Returns**:

- `string`: Formatted answer with sources

**Complete Method Flow**:

```go
func (s *SimpleLLM) GenerateResponse(question string, documents []models.Document) string {
    if len(documents) == 0 {
        return "I couldn't find any relevant information to answer your question based on the documents I have access to."
    }

    // 1. Build structured answer from documents
    answer := s.buildAnswerFromDocuments(question, documents)
    return answer
}
```

**Answer Structure**:

```
Based on the documents I found, here's the answer to your question:

**Question:** [User's question]

**Answer:** [Generated answer from documents]

**Sources:**
1. [Document ID 1]
2. [Document ID 2]
...
```

##### `buildAnswerFromDocuments(question string, documents []models.Document) string`

**Purpose**: Builds structured answer from document content.

**Complete Method Flow**:

```go
func (s *SimpleLLM) buildAnswerFromDocuments(question string, documents []models.Document) string {
    var answer strings.Builder

    // 1. Add header
    answer.WriteString("Based on the documents I found, here's the answer to your question:\n\n")
    answer.WriteString(fmt.Sprintf("**Question:** %s\n\n", question))
    answer.WriteString("**Answer:** ")

    // 2. Extract key information from documents
    for i, doc := range documents {
        if i == 0 {
            // Use the most relevant document as the main answer
            answer.WriteString(s.extractKeyInformation(doc.Content))
        } else if i < 3 {
            // Add supporting information from other relevant documents
            answer.WriteString(" ")
            answer.WriteString(s.extractSupportingInfo(doc.Content))
        }
    }

    // 3. Add sources section
    answer.WriteString("\n\n**Sources:**\n")
    for i, doc := range documents {
        answer.WriteString(fmt.Sprintf("%d. %s\n", i+1, doc.ID))
    }

    return answer.String()
}
```

**Strategy**:

- Uses most relevant document as primary answer
- Adds supporting information from other documents
- Maintains source attribution

##### `extractKeyInformation(content string) string`

**Purpose**: Extracts key information from document content.

**Complete Method Flow**:

```go
func (s *SimpleLLM) extractKeyInformation(content string) string {
    // Extract the most relevant sentence or key information
    sentences := strings.Split(content, ".")
    if len(sentences) > 0 {
        return strings.TrimSpace(sentences[0]) + "."
    }
    return content
}
```

**Method**: Takes first sentence as key information.

##### `extractSupportingInfo(content string) string`

**Purpose**: Extracts additional supporting information.

**Complete Method Flow**:

```go
func (s *SimpleLLM) extractSupportingInfo(content string) string {
    // Extract additional supporting information
    sentences := strings.Split(content, ".")
    if len(sentences) > 1 {
        return strings.TrimSpace(sentences[1]) + "."
    }
    return ""
}
```

**Method**: Uses second sentence as supporting information.

**Usage in RAG Pipeline**:

1. Called by RAGService.Query() after document retrieval
2. Processes retrieved documents to generate answers
3. Returns formatted response with sources

---

## File: `services/llama_service.go`

### Package: `services`

### `LlamaEmbedder` struct

#### Overview

Local/remote Llama embedding client for text-to-vector conversion via an embeddings endpoint (defaults to `http://localhost:8081/embeddings`).

#### Fields

```go
type LlamaEmbedder struct {
    BaseURL string      // Base URL for Llama embeddings service
    Client  *http.Client // HTTP client with timeout
}
```

#### Constructor

```go
func NewLlamaEmbedder() *LlamaEmbedder
```

**Purpose**: Initializes the Llama embedder with sensible defaults (30s timeout, base URL `http://localhost:8081`).

#### Methods

##### `CreateEmbedding(text string) ([]float32, error)`

**Purpose**: Calls the Llama embeddings service to convert input text into a vector.

**Request**:

```json
{
  "model": "llama-text-embed-v2",
  "input": ["<text>"]
}
```

**Response shape (expected)**:

```json
{
  "data": [ { "embedding": [0.1, 0.2, ...] } ]
}
```

**Errors**: Network failures, invalid JSON, empty data array.

**Usage in RAG Pipeline**:

1. Can be used as an alternative to `OpenAIEmbedder` for local embeddings
2. Plug-in replacement where an embedder is required (`RAGService`)

---

## File: `services/simple_llm_old.go`

### Package: `services`

### `SimpleLLM_old` struct (legacy)

#### Overview

Legacy/simple template-based response generator retained for backward compatibility and testing. Prefer `SimpleLLM` in `simple_llm.go`.

#### Constructor

```go
func NewSimpleLLM_old() *SimpleLLM
```

Note: Returns the current `SimpleLLM` implementation for compatibility.

#### Methods

##### `GenerateResponse_old(question string, documents []models.Document) string`

**Purpose**: Produces a basic textual response enumerating retrieved documents. Useful for debugging without formatting logic.

**Behavior**:

- Returns a fallback message if no documents
- Includes the question and counts/documents content in a simple template

**Status**: Deprecated. Use `SimpleLLM.GenerateResponse` instead.

---

## File: `handlers/query_handler.go`

### Package: `handlers`

### `QueryHandler` struct

#### Overview

HTTP handler for processing user queries.

#### Fields

```go
type QueryHandler struct {
    ragService models.RAGService // RAG service instance
}
```

#### Constructor

```go
func NewQueryHandler(ragService models.RAGService) *QueryHandler
```

#### Methods

##### `ServeHTTP(w http.ResponseWriter, r *http.Request)`

**Purpose**: Handles HTTP POST requests to `/query` endpoint.

**Complete Method Flow**:

```go
func (h *QueryHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) {
    // 1. Validate HTTP method
    if r.Method != http.MethodPost {
        http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
        return
    }

    // 2. Parse JSON request
    var request models.QueryRequest
    if err := json.NewDecoder(r.Body).Decode(&request); err != nil {
        http.Error(w, "Invalid JSON: "+err.Error(), http.StatusBadRequest)
        return
    }

    // 3. Process query through RAG service
    response, err := h.ragService.Query(request)
    if err != nil {
        http.Error(w, "Query failed: "+err.Error(), http.StatusInternalServerError)
        return
    }

    // 4. Send JSON response
    w.Header().Set("Content-Type", "application/json")
    json.NewEncoder(w).Encode(response)
    fmt.Printf(">>>>> Processed query: %s\n", request.Question)
}
```

**Request Format**:

```json
{
    "question": "What is machine learning?",
    "top_k": 3
}
```

**Response Format**:

```json
{
    "answer": "Based on the documents...",
    "sources": [
        {
            "id": "doc_001",
            "content": "Machine learning is...",
            "embedding": [0.1, 0.2, ...]
        }
    ]
}
```

**HTTP Methods**: POST only
**Error Handling**:

- Method not allowed (405)
- Invalid JSON (400)
- Query processing errors (500)

**Usage in Router**:

1. Registered at `/query` endpoint
2. Handles user question processing
3. Returns structured response with answer and sources

---

## File: `handlers/ingest_handler.go`

### Package: `handlers`

### `IngestHandler` struct

#### Overview

HTTP handler for adding documents to the system.

#### Fields

```go
type IngestHandler struct {
    ragService models.RAGService // RAG service instance
}
```

#### Constructor

```go
func NewIngestHandler(ragService models.RAGService) *IngestHandler
```

#### Methods

##### `ServeHTTP(w http.ResponseWriter, r *http.Request)`

**Purpose**: Handles HTTP POST requests to `/ingest` endpoint.

**Complete Method Flow**:

```go
func (h *IngestHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) {
    // 1. Validate HTTP method
    if r.Method != http.MethodPost {
        http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
        return
    }

    // 2. Parse JSON request
    var request models.IngestionRequest
    if err := json.NewDecoder(r.Body).Decode(&request); err != nil {
        http.Error(w, "Invalid JSON: "+err.Error(), http.StatusBadRequest)
        return
    }

    // 3. Process ingestion through RAG service
    if err := h.ragService.Ingest(request); err != nil {
        http.Error(w, "Ingestion failed: "+err.Error(), http.StatusInternalServerError)
        return
    }

    // 4. Send success response
    response := map[string]interface{}{
        "message":        "Documents added successfully",
        "document_count": len(request.Documents),
    }

    w.Header().Set("Content-Type", "application/json")
    json.NewEncoder(w).Encode(response)
    fmt.Printf(">>>>> Ingested %d documents\n", len(request.Documents))
}
```

**Request Format**:

```json
{
    "documents": [
        {
            "id": "doc_001",
            "content": "Machine learning is a subset of AI...",
            "embedding": []
        }
    ]
}
```

**Response Format**:

```json
{
    "message": "Documents added successfully",
    "document_count": 1
}
```

**HTTP Methods**: POST only
**Process**:

1. Validates JSON request
2. Calls RAG service ingest method
3. Returns success confirmation

**Usage in Router**:

1. Registered at `/ingest` endpoint
2. Handles document ingestion requests
3. Returns success confirmation with document count

---

## File: `handlers/heatlth_handler.go`

### Package: `handlers`

### `HealthHandler` struct

#### Overview

HTTP handler for health checks.

#### Constructor

```go
func NewHealthHandler() *HealthHandler
```

#### Methods

##### `ServeHTTP(w http.ResponseWriter, r *http.Request)`

**Purpose**: Handles HTTP GET requests to `/health` endpoint.

**Complete Method Flow**:

```go
func (h *HealthHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) {
    // 1. Validate HTTP method
    if r.Method != http.MethodGet {
        http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
        return
    }

    // 2. Create health response
    response := map[string]interface{}{
        "status":    "healthy",
        "service":   "simple-rag",
        "timestamp": time.Now().Format(time.RFC3339),
        "version":   "1.0.0",
    }

    // 3. Send JSON response
    w.Header().Set("Content-Type", "application/json")
    json.NewEncoder(w).Encode(response)
}
```

**Response Format**:

```json
{
    "status": "healthy",
    "service": "simple-rag",
    "timestamp": "2024-01-01T00:00:00Z",
    "version": "1.0.0"
}
```

**HTTP Methods**: GET only

**Usage in Router**:

1. Registered at `/health` endpoint
2. Provides system health status
3. Used for monitoring and load balancer health checks

---

## File: `handlers/not_found_handler.go`

### Package: `handlers`

### `NotFoundHandler` struct

#### Overview

HTTP handler for undefined routes.

#### Constructor

```go
func NewNotFoundHandler() *NotFoundHandler
```

#### Methods

##### `ServeHTTP(w http.ResponseWriter, r *http.Request)`

**Purpose**: Handles requests to undefined endpoints.

**Complete Method Flow**:

```go
func (h *NotFoundHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) {
    // 1. Create error response
    response := map[string]interface{}{
        "error":     "Endpoint not found",
        "path":      r.URL.Path,
        "method":    r.Method,
        "timestamp": time.Now().Format(time.RFC3339),
        "available_endpoints": []string{
            "GET /health",
            "POST /ingest",
            "POST /query",
        },
    }

    // 2. Send 404 response
    w.Header().Set("Content-Type", "application/json")
    w.WriteHeader(http.StatusNotFound)
    json.NewEncoder(w).Encode(response)
}
```

**Response Format**:

```json
{
    "error": "Endpoint not found",
    "path": "/unknown",
    "method": "GET",
    "timestamp": "2024-01-01T00:00:00Z",
    "available_endpoints": [
        "GET /health",
        "POST /ingest",
        "POST /query"
    ]
}
```

**HTTP Status**: 404 Not Found

**Usage in Router**:

1. Registered as catch-all handler at `/`
2. Handles all undefined routes
3. Provides helpful error message with available endpoints

---

## File: `router/router.go`

### Package: `router`

### `Router` struct

#### Overview

Configures HTTP routes and handlers.

#### Fields

```go
type Router struct {
    mux *http.ServeMux // HTTP request multiplexer
}
```

#### Constructor

```go
func NewRouter(ragService models.RAGService) *Router
```

**Purpose**: Creates router with all configured routes.

**Route Configuration**:

- `GET /health` â†’ HealthHandler
- `POST /ingest` â†’ IngestHandler
- `POST /query` â†’ QueryHandler
- `/*` â†’ NotFoundHandler (catch-all)

#### Methods

##### `GetHandler() http.Handler`

**Purpose**: Returns the configured HTTP handler.

**Complete Method Flow**:

```go
func (r *Router) GetHandler() http.Handler {
    return r.mux
}
```

**Returns**: `http.Handler` for server configuration

**Usage in Server**:

1. Called by main() to get HTTP handler
2. Passed to Server.NewServer() for configuration
3. Used by HTTP server for request routing

---

## File: `server/server.go`

### Package: `server`

### `Server` struct

#### Overview

Manages HTTP server lifecycle with graceful shutdown.

#### Fields

```go
type Server struct {
    httpServer *http.Server // HTTP server instance
}
```

#### Constructor

```go
func NewServer(addr string, handler http.Handler) *Server
```

**Purpose**: Creates server with configuration.

**Configuration**:

- Address: Server bind address
- Read Timeout: 15 seconds
- Write Timeout: 30 seconds
- Idle Timeout: 60 seconds

#### Methods

##### `Start() error`

**Purpose**: Starts the HTTP server in background goroutine.

**Complete Method Flow**:

```go
func (s *Server) Start() error {
    fmt.Println(":: Starting server on::", s.httpServer.Addr)

    // 1. Start server in background goroutine
    go func() {
        if err := s.httpServer.ListenAndServe(); err != nil && err != http.ErrServerClosed {
            fmt.Printf(":::::::::: Server failed::::::::: %v\n", err)
            os.Exit(1)
        }
    }()

    return nil
}
```

**Process**:

1. Starts server in background
2. Handles server errors
3. Exits on critical failures

##### `Shutdown(timeout time.Duration) error`

**Purpose**: Gracefully shuts down the server.

**Parameters**:

- `timeout`: Maximum shutdown duration

**Complete Method Flow**:

```go
func (s *Server) Shutdown(timeout time.Duration) error {
    fmt.Println(":::::::::: Shutting down server...::::::::::")

    // 1. Create shutdown context with timeout
    ctx, cancel := context.WithTimeout(context.Background(), timeout)
    defer cancel()

    // 2. Initiate graceful shutdown
    if err := s.httpServer.Shutdown(ctx); err != nil {
        return fmt.Errorf("shutdown failed: %v", err)
    }

    fmt.Println(":::::::::: Server shutdown gracefully ::::::::::")
    return nil
}
```

**Process**:

1. Creates shutdown context with timeout
2. Initiates graceful shutdown
3. Waits for connections to close

##### `WaitForShutdown()`

**Purpose**: Blocks until shutdown signal received.

**Complete Method Flow**:

```go
func (s *Server) WaitForShutdown() {
    // 1. Create signal channel
    signalChan := make(chan os.Signal, 1)
    signal.Notify(signalChan, os.Interrupt, syscall.SIGTERM)

    // 2. Wait for shutdown signal
    <-signalChan
    fmt.Println("\n ::::::::::Received shutdown signal::::::::::")

    // 3. Graceful shutdown with 10 second timeout
    if err := s.Shutdown(10 * time.Second); err != nil {
        fmt.Printf(":::::::::: Shutdown error: %v\n", err)
        os.Exit(1)
    }
}
```

**Signal Handling**:

- Listens for SIGINT (Ctrl+C)
- Listens for SIGTERM
- Triggers graceful shutdown

**Usage in Main**:

1. Called by main() after server start
2. Blocks until shutdown signal received
3. Handles graceful server shutdown

---

## File: `main.go`

### Package: `main`

### Application Entry Point

#### `main()` function

**Purpose**: Application initialization and startup.

**Complete Method Flow**:

```go
func main() {
    fmt.Println(":::::::::: Starting Simple RAG Server...::::::::::")
    fmt.Println("=================================")

    // 1. Initialize Pinecone
    fmt.Println("1. :::::::::: Setting up Pinecone...::::::::::")
    pc, err := pinecone.NewClient(pinecone.NewClientParams{
        ApiKey: "pcsk_7UZEUB_Diuc2pGmu48xStqZ947NjoNm2dSuwB2Tpvvxi5ogQua8uACh8ybuQQGChdAXdbS",
    })
    if err != nil {
        log.Fatalf(":::::::::: Failed to create Pinecone client: %v", err)
    }

    // 2. Initialize Services
    fmt.Println("2. ::::::::::  Initializing services...")
    pineconeService := services.NewVectorStore(pc, "rag-demo-ach4dab.svc.aped-4627-b74a.pinecone.io")
    fmt.Println("-->> Connected to Pinecone index <<--")
    embedder := services.NewOpenAIEmbedder()
    llm := services.NewSimpleLLM()
    ragService := services.NewRAGService(embedder, pineconeService, llm)

    // 3. Setup Router
    fmt.Println("3. ::::::::::  Setting up routes...::::::::::")
    appRouter := router.NewRouter(ragService)

    // 4. Start Server
    fmt.Println("4. ::::::::::: Starting server...")
    appServer := server.NewServer(":8080", appRouter.GetHandler())

    if err := appServer.Start(); err != nil {
        log.Fatalf(":::::::::: Failed to start server: %v", err)
    }

    // 5. Display startup info
    fmt.Println("=================================")
    fmt.Println(":::::::::: SERVER IS READY!::::::::::")
    fmt.Println(" URL: http://localhost:8080")
    fmt.Println(" Available endpoints:")
    fmt.Println("   GET  /health  - Health check")
    fmt.Println("   POST /ingest  - Add documents")
    fmt.Println("   POST /query   - Ask questions")
    fmt.Println("=================================")
    fmt.Println("  Press Ctrl+C to shutdown gracefully")
    fmt.Println("=================================")

    // 6. Wait for shutdown signal
    appServer.WaitForShutdown()
}
```

**Initialization Steps**:

1. **Pinecone Setup**: Creates Pinecone client with API key
2. **Service Initialization**: Sets up embedding, vector store, and LLM services
3. **RAG Service**: Combines all services into RAG pipeline
4. **Router Setup**: Configures HTTP routes
5. **Server Start**: Starts HTTP server on port 8080
6. **Signal Handling**: Waits for shutdown signal

**Configuration**:

- Pinecone API Key: `pcsk_7UZEUB_Diuc2pGmu48xStqZ947NjoNm2dSuwB2Tpvvxi5ogQua8uACh8ybuQQGChdAXdbS`
- Pinecone Index: `rag-demo-ach4dab.svc.aped-4627-b74a.pinecone.io`
- Server Port: `:8080`

**Available Endpoints**:

- `GET /health` - Health check
- `POST /ingest` - Add documents
- `POST /query` - Ask questions

**Application Flow**:

1. **Startup**: Initialize all services and dependencies
2. **Server**: Start HTTP server on port 8080
3. **Runtime**: Handle HTTP requests through RAG pipeline
4. **Shutdown**: Graceful shutdown on signal

---

## API Usage Examples

### Health Check

```bash
curl http://localhost:8080/health
```

### Ingest Documents

```bash
curl -X POST http://localhost:8080/ingest \
  -H "Content-Type: application/json" \
  -d '{
    "documents": [
      {
        "id": "doc_001",
        "content": "Machine learning is a subset of artificial intelligence that focuses on algorithms that can learn from data.",
        "embedding": []
      }
    ]
  }'
```

### Query System

```bash
curl -X POST http://localhost:8080/query \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What is machine learning?",
    "top_k": 3
  }'
```

---

## Error Handling

### Common Error Scenarios

1. **Network Errors**: OpenAI API failures, Pinecone connection issues
2. **Authentication Errors**: Invalid API keys
3. **Data Errors**: Invalid JSON, missing fields
4. **Processing Errors**: Embedding failures, vector search errors

### Error Response Format

```json
{
    "error": "Error description",
    "details": "Additional error information"
}
```

---

## Dependencies

### External Services

- **OpenAI API**: Text embedding generation
- **Pinecone**: Vector storage and similarity search

### Go Dependencies

- `github.com/pinecone-io/go-pinecone/v4`: Pinecone client
- `github.com/gin-gonic/gin`: HTTP framework (if used)
- `google.golang.org/protobuf/types/known/structpb`: Protocol buffer types

---

## Performance Considerations

### Embedding Generation

- OpenAI API rate limits
- 30-second timeout for API calls
- Batch processing for multiple documents

### Vector Storage

- Pinecone index capacity limits
- Vector dimension: 1536 (OpenAI text-embedding-3-small)
- Metadata storage for document content

### Search Performance

- Cosine similarity search
- Configurable top-K results
- Field selection for response optimization

---

## Security Considerations

### API Keys

- OpenAI API key embedded in code (should use environment variables)
- Pinecone API key embedded in code (should use environment variables)

### Input Validation

- JSON schema validation
- HTTP method validation
- Request size limits

### Error Information

- Detailed error messages in development
- Sanitized error responses in production

---

This documentation provides a comprehensive overview of all classes, functions, and their purposes in the Simple RAG project. Each component is designed to work together to create a complete retrieval-augmented generation system.
